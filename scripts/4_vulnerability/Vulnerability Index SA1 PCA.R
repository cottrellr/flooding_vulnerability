### ------------------------------------------------------------------------ ###
### ------------- CODE FOR CREATION OF VULNERABILITY INDEX SA1 ------------- ###
### ------------------------------------------------------------------------ ###


### Libraries: ------------------------------------------------------------- ###
### ------------------------------------------------------------------------ ###
library(sf)
library(tidyverse)
library(dplyr)
library(here)
library(data.table)
library(corrplot)
library(ggplot2)
library(tidyr)
library(corrr)
library(ggcorrplot)
library(factoextra)

### SHAPEFILE LOADING: ----------------------------------------------------- ###
### ------------------------------------------------------------------------ ###
BRIS <- read_sf("../../data/spatial/SA1_Bris","bris_sa1")
DF <- st_drop_geometry(BRIS)[,1]
fPath <- "../../data/processed_data/"
fPath2 <- "../../data/data_products/"


### NORMALISING FUNCTION: -------------------------------------------------- ###
### ------------------------------------------------------------------------ ###
normaliseData <- function(dummy){
  for (i in 2:ncol(dummy)){
    # Avoid modifying columns if they have a single unique value or are NA
    if(length(unique(dummy[, i])) > 1){
      dummy[, i] <- scale(dummy[, i])
    }
  }
  return(dummy)
}

### EXPOSURE (HIGH -> MORE VULNERABLE): ------------------------------------ ###
### ------------------------------------------------------------------------ ###
DF_E <- DF

# Inundation:
DATASET_E <- c("sa1_inundation")
for (i in 1:length(DATASET_E)){
  new <- read.csv(paste0(fPath2,DATASET_E[i],".csv"))
  new <- new[,c(1, ncol(new))]
  names(new)[1] <- "SA1_CODE21"
  DF_E <- merge(DF_E,new)
}

# Normalise instead of rank
DF_E <- normaliseData(DF_E)

if(ncol(DF_E) == 2){
  # Quick counter-measure while inundation is our only exposure parameter
  DF_E <- cbind(DF_E, "EXP" = DF_E[,2])
} 

# Does it look normally distributed? If not, apply a transform
hist(DF_E$EXP, breaks = 100) # Definitely right-skewed, so use log tform
DF_E$EXP <- log(DF_E$EXP + 1) # Adding 1 to avoid log(0)
hist(DF_E$EXP, breaks = 100) # Still right-skewed

# Plot Exposure (Revisit to adjust score representation)
PLOT <- merge(BRIS,DF_E)
ggplot() +
  geom_sf(data=PLOT, aes(fill = EXP), color="black") +
  theme_void() +
  # scale_fill_gradientn(colours = c("#C3DFCC", "#81C3D1",  "#579cc6", "#406ba8", "#2a3b8a", "#1b1f5d")) +
  scale_fill_distiller(direction = 1) +
  labs(fill="Exposure Score")


### SENSITIVITY (HIGH -> MORE VULNERABLE): --------------------------------- ###
### ------------------------------------------------------------------------ ###
DF_S <- DF

# Set sensitivity themes & variables within themes
S_THEMES <- list(
  # Socioeconomic Status (missing income status)
  soc_econ_stat = c("Population2021",
                    "edu2021",
                    "unemployed2021"),
  # Household Composition (missing single parents, living alone)
  house_comp = c("vulnerable_young2021",
                 "vulnerable_old2021",
                 "disabl2021"),
  # Language and Culture
  lang_culture = c("esl2021", 
                   "indigenous2021"),
  # Housing Conditions
  house_cond = c("dwell_house2021",
                 "familydwelling2021"),
  # Health Status 
  health_stat = c("long-term_health_cond2021")
  # Health Risk Factors 
  #health_risk = c()
)

# ABS Demographics:
DATASET_S <- c("disabl2021",
               "dwell_house2021",
               "edu2021",
               "vulnerable_young2021",
               "vulnerable_old2021",
               "unemployed2021",
               "esl2021",
               "indigenous2021",
               "long-term_health_cond2021",
               "Population2021",
               "familydwelling2021")

# Read the files for each of the sensitivity elements
for (i in 1:length(DATASET_S)){
  new <- read.csv(paste0(fPath, "SA1/", DATASET_S[i], ".csv"))
  new <- new[, c(1, ncol(new))]
  names(new) <- c("SA1_CODE21", DATASET_S[i])
  DF_S <- merge(DF_S, new)
}    

DF_S_long <- pivot_longer(DF_S, cols = -1)
# ggplot(DF_S$vulnerable_old2021) + 
#   geom_histogram(bins = 75)
hist(DF_S$vulnerable_old2021)
ggplot(filter(DF_S_long, name == "vulnerable_old2021",
              value > 0), aes(x = value)) + 
  geom_histogram(bins = 75) +
  facet_wrap(~name, scales = "free") +
  theme_minimal() +
  labs(x = "Value", y = "Frequency")
summary(DF_S$vulnerable_old2021)

test <- merge(BRIS, filter(DF_S_long, name == "vulnerable_old2021",
                           value < 1))
ggplot(test) +
  geom_sf(color = NA, aes(fill = value)) +
  xlim(c(152.8,153)) +
  ylim(c(-28,-27))

# Set any outliers more than 2 std from mean to min or max depending
for(column in 2:ncol(DF_S)){
  # Determine outliers
  lower_bound <- quantile(DF_S[, column], 0.025, na.rm = T)
  upper_bound <- quantile(DF_S[, column], 0.975, na.rm = T)
  outlier_ind_low <- which(DF_S[, column] < lower_bound)
  outlier_ind_high <- which(DF_S[, column] > upper_bound)
  
  # Set any outliers more than 2 std from mean to min or max depending
  if (length(outlier_ind_low) > 0) {
    DF_S[outlier_ind_low, column] <- min(DF_S[-outlier_ind_low, column], 
                                         na.rm = T)
  }
  
  if (length(outlier_ind_high) > 0) {
    DF_S[outlier_ind_high, column] <- max(DF_S[-outlier_ind_high, column], 
                                          na.rm = T)
  }
}

# Normalise the data
DF_S_colnames <- colnames(DF_S)
DF_S <- normaliseData(DF_S)
colnames(DF_S) <- DF_S_colnames

# Produce correlation plot
corr_matrix <- cor(DF_S[, 2:ncol(DF_S)],
                   use = "na.or.complete")
ggcorrplot(corr_matrix)

# PCA overall
data.pca <- princomp(corr_matrix)
summary(data.pca)
fviz_eig(data.pca, addlabels = TRUE) #scree

# Plot histograms
DF_S_long <- pivot_longer(DF_S, cols = -1)
ggplot(DF_S_long, aes(x = value)) + 
  geom_histogram(bins = 75) +
  facet_wrap(~name, scales = "free") +
  theme_minimal() +
  labs(x = "Value", y = "Frequency")
summary(DF_S)

# PCA for each theme
# Initialize lists to store results
s_theme_results <- list()
for (s_theme_name in names(S_THEMES)) {
  # Initialize a list for this theme
  results <- list()
  
  s_theme <- S_THEMES[[s_theme_name]]
    
  if (length(s_theme) > 1) {
    
    # Correlation plot of the theme
    theme_corr_matrix <- cor(DF_S[, s_theme],
                             use = "na.or.complete")
    ggcorrplot(theme_corr_matrix)
    results$corr_matrix <- theme_corr_matrix
    results$corr_plot <- ggcorrplot(theme_corr_matrix)
    
    # PCA of the theme
    theme_data.pca <- princomp(theme_corr_matrix)
    results$pca_summary <- summary(theme_data.pca)
    results$pca_loadings <- theme_data.pca$loadings
    
    # Scree plot
    results$scree_plot <- fviz_eig(theme_data.pca, addlabels = TRUE)
    
    # PCA variables plot
    results$pca_var_plot <- fviz_pca_var(theme_data.pca, col.var = "black")
  }
  
  # Store all results for this theme in the main list
  s_theme_results[[s_theme_name]] <- results
}
s_theme_results$soc_econ_stat$pca_loadings
s_theme_results$house_comp$pca_loadings

# Q: What values from above PCA to complete below PCA? -------------------------

# Task: (Change to) PCA across themes

PLOT <- merge(BRIS, DF_S)
ggplot() +
  geom_sf(data=PLOT, aes(fill = SEN), color="black") +
  # scale_fill_gradientn(colours = c("#f9eb73", "#eec259",  "#e39642", "#d96a2e", "#ae4e29", "#663d2f")) +
  scale_fill_distiller(palette = "YlOrBr", direction = 1) +
  theme_void() +
  labs(fill="Sensitivity (%)")


### ADAPTIVE CAPACITY (HIGH -> MORE VULNERABLE): --------------------------- ###
### ------------------------------------------------------------------------ ###
DF_A <- DF

# Distance to services:
DATASET_A <- c("dAmbu",
               "dBuss",
               "dFire",
               "dHosp",
               "dPets",
               "dPoli",
               "dSesf",
               "dShop")

# Read the files for each of the sensitivity elements
for (i in 1:length(DATASET_A)){
  new <- read.csv(paste0(fPath,"SA1/",DATASET_A[i],".csv"))[,-1]
  DF_A <- merge(DF_A,new)
}

# Normalise the data
DF_A_colnames <- colnames(DF_A)
DF_A <- normaliseData(DF_A)
colnames(DF_A) <- DF_A_colnames

# Plot histograms
DF_A_long <- pivot_longer(DF_A, cols = -1)
ggplot(DF_A_long, aes(x = value)) + 
  geom_histogram(bins = 75) +
  facet_wrap(~name, scales = "free") +
  theme_minimal() +
  labs(x = "Value", y = "Frequency")
summary(DF_A)

# Set Adaptive Capacity themes & variables within themes
A_THEMES <- list(
  # Emergency Services
  emerg_service = c("dAmbu",
                    "dFire",
                    "dPoli",
                    "dSesf"),
  # Health Services
  health_service = c("dHosp"),
  # Necessities?
  necessities = c("dBuss",
                  "dPets", 
                  "dShop")
)

# (Change to) PCA for each theme
for (theme in A_THEMES) {
  for(element in theme) {
    # Get the column index
    element_indx <- which(colnames(DF_A) == element)
    
    
  }
  # PCA of the theme
  
}

# (Change to) PCA across themes

PLOT <- merge(BRIS,DF_A)
ggplot() +
  geom_sf(data=PLOT, aes(fill = AC), color="black") +
  # scale_fill_gradientn(colours = rev(c("#eeb6a3", "#df7890",  "#bd4c8a", "#7e2d91", "#52157f", "#381754"))) +
  scale_fill_distiller(palette = 'YlGn') +
  theme_void() +
  labs(fill="Adaptive Capacity (%)")


### VULNERABILITY (HIGH -> MORE VULNERABLE): ------------------------------- ###
### ------------------------------------------------------------------------ ###

DF_V <- merge(DF_E,DF_S) %>% merge(DF_A)
dummy <- cbind(DF_V$EXP,DF_V$SEN,DF_V$AC)
DF_V <- cbind(DF_V, "VI" = frank(rowSums(dummy), 
                                 na.last = "keep", 
                                 ties.method = c("min"))/nrow(dummy))

PLOT <- merge(BRIS,DF_V)
ggplot() +
  geom_sf(data=PLOT, aes(fill = VI), color="black") +
  scale_fill_viridis_c(option = "rocket", direction = -1, begin = 0.2) +
  # scale_fill_distiller(palette = 'BuPu', direction = 1) +
  theme_void() +
  labs(fill="Vulnerability (%)")

# Correlation plot:
corrplot(cor(DF_V[,2:ncol(DF_V)],use="complete.obs"))



# ---------------------------------------------------------------------------- #